{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Execution Description\n",
    "\n",
    "```{note}\n",
    "執行程式方法：\n",
    "\n",
    "所有用到的手寫函數放置於 functions.py，其餘針對每題均個別寫一個 python 程式，以 problem1.py, problem2.py, ..., problem6.py 依序命名。\n",
    "執行時，只要針對執行欲求題目之程式即可。例如想執行回答第一題的程式，就在終端機輸入：\n",
    "    ```\n",
    "    python problem1.py\n",
    "    ```\n",
    "```\n",
    "\n",
    "以下區塊是實做細節。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KFold\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# functions.py 內容\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def genSample(dataNum, isPrint):\n",
    "    # Create data points\n",
    "    X = torch.linspace(-3, 3, steps=dataNum).unsqueeze(0)\n",
    "    Noise = torch.rand(1, dataNum)\n",
    "    Y = 2*X + Noise\n",
    "    data = torch.stack((X,Y), 0)\n",
    "\n",
    "    # Plot\n",
    "    if(isPrint == 1):\n",
    "        plt.scatter(X, Y, color='blue')\n",
    "        x = np.linspace(-3,3,100)\n",
    "        plt.plot(x, 2*x, color='black')\n",
    "\n",
    "        plt.title('Scatter plot of 2D data samples')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.show()\n",
    "\n",
    "    return data\n",
    "\n",
    "def genSampleSin(dataNum, isPrint):\n",
    "    # Create data points\n",
    "    X = torch.linspace(0, 1, steps=dataNum).unsqueeze(0)\n",
    "    Noise = torch.rand(1, dataNum)*0.04\n",
    "    Y = torch.sin(2*math.pi*X) + Noise\n",
    "    data = torch.stack((X,Y), 0)\n",
    "\n",
    "    # Plot\n",
    "    if(isPrint == 1):\n",
    "        plt.scatter(X, Y, color='blue')\n",
    "        x = np.arange(0, 1, 0.01)\n",
    "        y = np.sin(2 * np.pi * x)\n",
    "        plt.plot(x, y, color='black')\n",
    "\n",
    "        plt.title('Scatter plot of 2D data samples')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.show()\n",
    "\n",
    "    return data\n",
    "\n",
    "def plot_polynomial(X, Y, coefficients):\n",
    "    # for y = 2 * x\n",
    "    plt.scatter(X, Y, color='blue')\n",
    "    x = torch.linspace(-3,3,1000)\n",
    "    plt.plot(x, 2*x, color='black')\n",
    "    coefficients = torch.flip(coefficients, dims = [0])\n",
    "\n",
    "    y = torch.zeros_like(x)\n",
    "\n",
    "    for i, c in enumerate(coefficients):\n",
    "        y += c * torch.pow(x, i)\n",
    "\n",
    "    plt.plot(x.numpy(), y.numpy())\n",
    "    plt.xlim(-3, 3)\n",
    "    plt.ylim(-6, 8)\n",
    "    plt.show()\n",
    "\n",
    "def plot_polynomial2(X, Y, coefficients):\n",
    "    # for y = sin(2 * pi * x)\n",
    "    plt.scatter(X, Y, color='blue')\n",
    "    x = np.arange(-10, 10, 0.01)\n",
    "    y = np.sin(2 * np.pi * x)\n",
    "    plt.plot(x, y, color='black')\n",
    "\n",
    "    coefficients = torch.flip(coefficients, dims = [0])\n",
    "    x = torch.linspace(-3,3,1000)\n",
    "    y = torch.zeros_like(x)\n",
    "\n",
    "    for i, c in enumerate(coefficients):\n",
    "        y += c * torch.pow(x, i)\n",
    "\n",
    "    plt.plot(x.numpy(), y.numpy())\n",
    "    #plt.xlim(-2, 2)\n",
    "    #plt.ylim(-10, 10)\n",
    "    plt.show()\n",
    "\n",
    "def LinearRegTrain(X, Y, origX, opt):\n",
    "    # only find trian error for Linear Regression\n",
    "    # W = (X.T * X)^(-1) * X.T * Y\n",
    "    W = (torch.mm(X.T, X)).inverse()\n",
    "    W = torch.mm(W, X.T)\n",
    "    W = torch.mm(W, Y)\n",
    "    \n",
    "    #  Plot\n",
    "    if(opt == 1):\n",
    "        plot_polynomial(origX[:,0], Y , W)\n",
    "    elif(opt == 2):\n",
    "        plot_polynomial2(origX[:,0], Y , W)\n",
    "\n",
    "    # Training Error\n",
    "    Y_pred = torch.mm(X, W)\n",
    "    MSE = mean_squared_error(Y, Y_pred)\n",
    "    \n",
    "    return MSE\n",
    "\n",
    "def LinearRegCV(X_train, Y_train, X_test, Y_test):\n",
    "    # Find validation error for a trained Linear Regression\n",
    "    # W = (X.T * X)^(-1) * X.T * Y\n",
    "    W = (torch.mm(X_train.T, X_train)).inverse()\n",
    "    W = torch.mm(W, X_train.T)\n",
    "    W = torch.mm(W, Y_train)\n",
    "\n",
    "    # Test Error\n",
    "    Y_pred = torch.mm(X_test, W)\n",
    "    MSE = mean_squared_error(Y_test, Y_pred)\n",
    "    \n",
    "    return MSE\n",
    "\n",
    "def LinearRegRegularCV(X_train, Y_train, X_test, Y_test, n, lambd):\n",
    "    # Find validation error for a trained Linear Regression\n",
    "    # W = (X.T * X + lanbda * I)^(-1) * X.T * Y\n",
    "    W = (torch.mm(X_train.T, X_train))#.inverse()\n",
    "    W = (W + lambd * torch.eye(n)).inverse()\n",
    "    W = torch.mm(W, X_train.T)\n",
    "    W = torch.mm(W, Y_train)\n",
    "\n",
    "    # Test Error\n",
    "    Y_pred = torch.mm(X_test, W)\n",
    "    MSE = mean_squared_error(Y_test, Y_pred)\n",
    "    \n",
    "    return MSE\n",
    "\n",
    "def prob3(X, Y, n, opt):\n",
    "    # Make X be a n degree tensor\n",
    "    poly = PolynomialFeatures(n)\n",
    "    polyX = poly.fit_transform(X)\n",
    "    polyX = torch.from_numpy(polyX).type(torch.float)\n",
    "\n",
    "    # Find the training error & plot\n",
    "    MSE = LinearRegTrain(polyX, Y , X, opt)\n",
    "    print(\"Training error: \", MSE)\n",
    "\n",
    "    # 5-fold cross validation\n",
    "    kf = KFold(n_splits = 5)\n",
    "    for (train_index, test_index) in kf.split(polyX):\n",
    "        X_train, X_test = polyX[train_index], polyX[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        curMSE = LinearRegCV(X_train, Y_train, X_test, Y_test)\n",
    "        MSE = MSE + curMSE\n",
    "\n",
    "    MSE = MSE / 5\n",
    "    print(\"5-fold cross validation error: \", MSE)\n",
    "\n",
    "def prob6(X, Y, n, lambd):\n",
    "    # Make X be a n degree tensor\n",
    "    poly = PolynomialFeatures(n)\n",
    "    polyX = poly.fit_transform(X)\n",
    "    polyX = torch.from_numpy(polyX).type(torch.float)\n",
    "\n",
    "    # Find the training error & plot\n",
    "    MSE = LinearRegTrain(polyX, Y , X, 2)\n",
    "\n",
    "    # 5-fold cross validation\n",
    "    kf = KFold(n_splits = 5)\n",
    "    for (train_index, test_index) in kf.split(polyX):\n",
    "        X_train, X_test = polyX[train_index], polyX[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        curMSE = LinearRegRegularCV(X_train, Y_train, X_test, Y_test, n+1, lambd)\n",
    "        MSE = MSE + curMSE\n",
    "\n",
    "    MSE = MSE / 5\n",
    "    print(\"5-fold cross validation error: \", MSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 問題一\n",
    "\n",
    "產生 x 為 -3~3 之間的隨機數字，且equal spacing，而 y 為 x 乘上 2 再加上 0~1 隨機雜訊所得之 data points："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genSample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenSample\u001b[49m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genSample' is not defined"
     ]
    }
   ],
   "source": [
    "genSample(15, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 問題二\n",
    "\n",
    "###  linear regression (for only training data):\n",
    "\n",
    "輸入 X, Y 和資料點的數量，就會進行線性回歸，且這個函式最後會回傳 training error。由於之後的題目會需要把原本二維的 X 轉換到高維。\n",
    "\n",
    "origX 是原本的一維 X 資料，為了能在同個函式裡面一起畫圖，我們最後一個參數傳入原始的 X。而opt 用來選擇畫圖時的基準線，如果是 1，會畫出 $y = 2x$ 的黑色直線，如果是2，會畫出 $y = sin(2πx)$ 的黑色波形。\n",
    "\n",
    "這個函式用於找 training error。\n",
    "\n",
    "#### linear regression (for both training & validation data):\n",
    "\n",
    "輸入訓練和測試資料進行線性回歸，函數最後回傳 testing error。\n",
    "\n",
    "這個函式用在做 cross validation 時，計算平均 testing error。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dat points\n",
    "dataSet = genSample(15, 0)\n",
    "ones = torch.ones(15, 1)\n",
    "X = dataSet[0].T\n",
    "X = torch.cat((X, ones), dim = 1)\n",
    "Y = dataSet[1].T\n",
    "\n",
    "# Find the training error\n",
    "MSE = LinearRegTrain(X, Y, X, 1)\n",
    "print(\"Training error: \", MSE)\n",
    "\n",
    "# 5-fold cross validation\n",
    "kf = KFold(n_splits = 5)\n",
    "MSE = 0\n",
    "for (train_index, test_index) in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    curMSE = LinearRegCV(X_train, Y_train, X_test, Y_test)\n",
    "    MSE = MSE + curMSE\n",
    "\n",
    "MSE = MSE / 5\n",
    "print(\"5-fold cross validation error: \", MSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.3 問題三\n",
    "\n",
    "在這個函式中先產生資料點，並拿三種指定維度的多項式擬合。\n",
    "\n",
    "我將過程包入函式 prob3(X, Y, n, opt) 中，其中 n 是多項式的維度，opt 用來選擇畫圖時的基準線，如果是 1，會畫出 $y = 2x$ 的黑色直線，如果是2，會畫出 $y = sin(2πx)$ 的黑色波形。\n",
    "\n",
    "在這裡，進行 linear regression 之前，先利用 sklearn 的 LinearRegTrain，將原本只有一維的 X 資料，轉為指定維度的特徵向量。而後進行步驟與第二題相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dat points\n",
    "dataSet = genSample(15, 0)\n",
    "X = dataSet[0].T      \n",
    "Y = dataSet[1].T\n",
    "\n",
    "# degree 5 \n",
    "print('DEGREE 5:')\n",
    "prob3(X, Y, 5, 1)\n",
    "\n",
    "# degreer 10 \n",
    "print('DEGREE 10:')\n",
    "prob3(X, Y, 10, 1)\n",
    "\n",
    "# drgree 15\n",
    "print('DEGREE 14:')\n",
    "prob3(X, Y, 14, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.4 問題四\n",
    "\n",
    "在問題四時，新寫一個產生 sin 資料點的函式，而其餘部份使用之函數與 main 架構均與第二與第三題相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data ================================\n",
    "dataSet = genSampleSin(15, 1)\n",
    "X = dataSet[0].T\n",
    "Y = dataSet[1].T\n",
    "\n",
    "# Linear Regression =============================\n",
    "print('Linear Regression=====================================')\n",
    "ones = torch.ones(15, 1)\n",
    "X = torch.cat((X, ones), dim = 1)\n",
    "# Find the training error\n",
    "MSE = LinearRegTrain(X, Y, X, 2)\n",
    "print(\"Training error: \", MSE)\n",
    "\n",
    "# 5-fold cross validation\n",
    "kf = KFold(n_splits = 5)\n",
    "MSE = 0\n",
    "for (train_index, test_index) in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    curMSE = LinearRegCV(X_train, Y_train, X_test, Y_test)\n",
    "    MSE = MSE + curMSE\n",
    "\n",
    "MSE = MSE / 5\n",
    "print(\"5-fold cross validation error: \", MSE)\n",
    "print('\\n')\n",
    "\n",
    "# Polynomial  Regression ==========================\n",
    "print('Polynomial Regression==================================')\n",
    "X = dataSet[0].T\n",
    "# degree 5 \n",
    "print('DEGREE 5:')\n",
    "prob3(X, Y, 5, 2)\n",
    "print('\\n')\n",
    "\n",
    "# degreer 10 \n",
    "print('DEGREE 10:')\n",
    "prob3(X, Y, 10, 2)\n",
    "print('\\n')\n",
    "\n",
    "# drgree 15\n",
    "print('DEGREE 14:')\n",
    "prob3(X, Y, 14, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 問題五\n",
    "\n",
    "產生不同資料點數量，並畫出擬合圖形即計算error，main function 架構如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 data points ==========================\n",
    "dataSet = genSampleSin(10, 1)\n",
    "X = dataSet[0].T\n",
    "Y = dataSet[1].T\n",
    "\n",
    "print('10 DATA POINTS:')\n",
    "prob3(X, Y, 14, 2)\n",
    "print('\\n')\n",
    "\n",
    "# 80 data points ==========================\n",
    "dataSet = genSampleSin(80, 1)\n",
    "X = dataSet[0].T\n",
    "Y = dataSet[1].T\n",
    "\n",
    "print('80 DATA POINTS:')\n",
    "prob3(X, Y, 14, 2)\n",
    "print('\\n')\n",
    "\n",
    "# 320 data points =========================\n",
    "dataSet = genSampleSin(320, 1)\n",
    "X = dataSet[0].T\n",
    "Y = dataSet[1].T\n",
    "\n",
    "print('320 DATA POINTS:')\n",
    "prob3(X, Y, 14, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 問題六\n",
    "\n",
    "prob6 是類似 prob3 的函式，只是其中使用正規化的函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data ================================\n",
    "# m = 15\n",
    "dataSet = genSampleSin(15, 1)\n",
    "X = dataSet[0].T\n",
    "Y = dataSet[1].T\n",
    "\n",
    "# regularization ===============================\n",
    "# lambda = 0\n",
    "print('lambda = 0')\n",
    "prob6(X, Y, 14, 0)\n",
    "\n",
    "# lambda = 0.001/m\n",
    "print('lambda = 0.001/m')\n",
    "prob6(X, Y, 14, 0.001/15)\n",
    "\n",
    "# lambda = 0, 1/m\n",
    "print('lambda = 1/m')\n",
    "prob6(X, Y, 14, 1/15)\n",
    "\n",
    "# lambda = 0, 1000/m\n",
    "print('lambda = 1000/m')\n",
    "prob6(X, Y, 14, 1000/15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
